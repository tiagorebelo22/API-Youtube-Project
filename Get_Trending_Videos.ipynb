{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b4d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "api_key = \"AIzaSyAlVD2T_l7kJ8No2_fFKSZVOk_LuI0foSM\"\n",
    "\n",
    "headers = [\"video_id\", \"title\", \"publish_time\", \"channelId\", \"channel_title\",\"category_id\",\"trending_date\", \"views\", \"likes\",\"comment_count\", \"comments_disabled\", \"ratings_disabled\", \"description\"]\n",
    "\n",
    "def api_request(page_token, country_code):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/videos?part=id,statistics,snippet\"+page_token+\"chart=mostPopular&regionCode=\"+country_code+\"&maxResults=50&key=\"+api_key\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def get_videos_info(items):\n",
    "    lines = []\n",
    "    for video in items:\n",
    "        comments_disabled = False\n",
    "        ratings_disabled = False\n",
    "\n",
    "        # Extract the required data\n",
    "        \n",
    "        video_id = video[\"id\"]\n",
    "        \n",
    "        snippet = video['snippet'] # dictionary\n",
    "        statistics = video['statistics'] # dictionary\n",
    "\n",
    "        # get data from the snippet dictionary\n",
    "        title = snippet.get(\"title\", \"\")\n",
    "        publishedAt = snippet.get(\"publishedAt\", \"\")   \n",
    "        channelId = snippet.get(\"channelId\", \"\")  \n",
    "        channelTitle = snippet.get(\"channelTitle\", \"\")  \n",
    "        categoryId = snippet.get(\"categoryId\", \"\")  \n",
    "        description = snippet.get(\"description\", \"\")\n",
    "        \n",
    "        # get current date\n",
    "        trending_date = time.strftime(\"%y.%d.%m\")\n",
    "        \n",
    "        # get data from the statistics dictionary\n",
    "        view_count = statistics.get(\"viewCount\", 0)\n",
    "\n",
    "        if 'likeCount' in statistics:\n",
    "            likes = statistics['likeCount']\n",
    "        else:\n",
    "            ratings_disabled = True\n",
    "            likes = 0\n",
    "\n",
    "        if 'commentCount' in statistics:\n",
    "            comment_count = statistics['commentCount']\n",
    "        else:\n",
    "            comments_disabled = True\n",
    "            comment_count = 0    \n",
    "\n",
    "        # aggregate all the data in one list\n",
    "        line = [video_id,\n",
    "                title,\n",
    "                publishedAt,\n",
    "                channelId,\n",
    "                channelTitle,\n",
    "                categoryId,\n",
    "                trending_date,\n",
    "                view_count,\n",
    "                likes,\n",
    "                comment_count,\n",
    "                comments_disabled,\n",
    "                ratings_disabled, \n",
    "                description]\n",
    "\n",
    "        # remove new lines and double quotes and append the list to the list of videos\n",
    "        line = [str(element).replace(\"\\n\",\"\").replace(chr(34),\"\") for element in line]\n",
    "        lines.append(line)\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def get_pages(country_code, next_page_token):\n",
    "    country_data = []\n",
    "    # The API uses page tokens. The next page token is provided in the response.\n",
    "    while next_page_token is not None:\n",
    "        # A page of data, meaning a list of videos\n",
    "        content_of_page = api_request(next_page_token, country_code)\n",
    "\n",
    "        # Get the next page token, unless it is None, which ends the loop after this cycle\n",
    "        next_page_token = content_of_page.get(\"nextPageToken\", None)\n",
    "        next_page_token = \"&pageToken=\"+next_page_token+\"&\" if next_page_token is not None else next_page_token\n",
    "\n",
    "        # Get all of the items as a list and let get_videos_info return the needed features\n",
    "        items = content_of_page.get('items', [])\n",
    "        country_data.extend(get_videos_info(items))\n",
    "\n",
    "    return country_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6695ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT extracted\n",
      "ES extracted\n",
      "KE extracted\n",
      "GR extracted\n",
      "NP extracted\n",
      "BR extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract the info for all the chosen countries\n",
    "\n",
    "country_codes=[\"PT\",\"ES\",\"KE\",\"GR\",\"NP\",\"BR\"]\n",
    "\n",
    "for code in country_codes:\n",
    "    video_info = pd.DataFrame(get_pages(code, next_page_token = \"&\"))\n",
    "    video_info.columns = headers\n",
    "    video_info.to_csv(\"Recent_DataSet/Recent_\"+code+\".csv\", index=False)\n",
    "    print(code + \" extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67a6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfc415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
